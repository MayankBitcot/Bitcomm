"""
OpenAI Whisper Transcription Module

Main transcriber class for converting audio to text using OpenAI's Whisper API.
"""

from pathlib import Path
from typing import Any, BinaryIO, Dict, Optional, Union

import openai
from openai import OpenAI

from ragent.log_utils import logger
from ragent.openai_constants import OpenAIConfig
from ragent.transcribe.base import BaseTranscriber

from .constants import DEFAULT_HALLUCINATION_KEYWORDS, DEFAULT_HALLUCINATION_PHRASES
from .exceptions import (
    AudioValidationError,
    HallucinationDetectedError,
    WhisperAPIError,
    WhisperTranscriptionError,
)
from .utils import (
    cleanup_temp_file,
    create_temp_audio_file,
    detect_file_extension,
    read_audio_file,
    validate_audio_size,
)


class WhisperTranscriber(BaseTranscriber):
    """
    OpenAI Whisper transcription client.

    Supports multiple audio formats, automatic language detection, and hallucination filtering.
    """

    def __init__(
        self,
        api_key: str = OpenAIConfig.API_KEY,
        model: str = "whisper-1",
        min_audio_size: int = 1024,
        min_transcript_length: int = 3,
        hallucination_check_enabled: bool = True,
        hallucination_phrases: Optional[list] = None,
        hallucination_keywords: Optional[list] = None,
    ):
        """
        Initialize Whisper transcriber.

        Args:
            api_key: OpenAI API key (defaults to OPENAI_API_KEY env var)
            model: Whisper model to use (default: "whisper-1")
            min_audio_size: Minimum audio file size in bytes (default: 1024)
            min_transcript_length: Minimum transcript length in characters (default: 3)
            hallucination_check_enabled: Enable hallucination detection (default: True)
            hallucination_phrases: Custom hallucination phrases to check
            hallucination_keywords: Custom hallucination keywords to check
            logger: Custom logger instance
        """
        self.api_key = api_key

        self.client = OpenAI(api_key=self.api_key)
        self.model = model
        self.min_audio_size = min_audio_size
        self.min_transcript_length = min_transcript_length
        self.hallucination_check_enabled = hallucination_check_enabled
        self.logger = logger

        # Use custom or default hallucination patterns
        self.hallucination_phrases = (
            hallucination_phrases or DEFAULT_HALLUCINATION_PHRASES
        )
        self.hallucination_keywords = (
            hallucination_keywords or DEFAULT_HALLUCINATION_KEYWORDS
        )

    def transcribe(
        self,
        audio_input: Union[str, Path, bytes, BinaryIO],
        filename: Optional[str] = None,
        content_type: Optional[str] = None,
        prompt: Optional[str] = None,
        language: Optional[str] = None,
        response_format: str = "verbose_json",
        temperature: Optional[float] = None,
    ) -> Dict[str, Any]:
        """
        Transcribe audio file synchronously.

        Args:
            audio_input: Audio file path, Path object, bytes, or file-like object
            filename: Optional filename for extension detection
            content_type: Optional MIME type for extension detection
            prompt: Optional prompt to guide Whisper's style or vocabulary
            language: Optional language code (ISO-639-1). If None, auto-detects.
            response_format: Response format ("json", "text", "srt", "verbose_json", "vtt")
            temperature: Sampling temperature (0.0 to 1.0). Higher = more random.

        Returns:
            Dictionary with keys:
                - transcript: Transcribed text
                - language: Detected language code
                - duration: Audio duration in seconds (if available)
                - words: Word-level timestamps (if verbose_json)

        Raises:
            AudioValidationError: If audio validation fails
            HallucinationDetectedError: If hallucination is detected
            WhisperAPIError: If OpenAI API returns an error
            WhisperTranscriptionError: For other transcription errors
        """
        temp_file_path = None

        try:
            # Read audio data
            if isinstance(audio_input, bytes):
                audio_data = audio_input
            else:
                audio_data = read_audio_file(audio_input)

            # Validate audio size
            validate_audio_size(audio_data, self.min_audio_size)

            # Detect file extension
            if isinstance(audio_input, (str, Path)):
                filename = filename or str(audio_input)

            file_extension = detect_file_extension(filename, content_type)
            self.logger.debug(f"Detected file extension: {file_extension}")

            # Create temporary file (Whisper API requires file path)
            temp_file_path = create_temp_audio_file(audio_data, file_extension)
            self.logger.debug(f"Created temp file: {temp_file_path}")

            # Call Whisper API
            self.logger.info("Calling Whisper API for transcription...")

            with open(temp_file_path, "rb") as audio_file:
                transcription = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    prompt=prompt,
                    language=language,
                    response_format=response_format,
                    temperature=temperature,
                )

            # Extract transcript and metadata
            transcript_text = (
                transcription.text.strip()
                if hasattr(transcription, "text")
                else str(transcription).strip()
            )
            detected_language = getattr(transcription, "language", None)

            self.logger.info(f"Transcription complete. Language: {detected_language}")
            self.logger.debug(f"Transcript: {transcript_text}")

            # Validate and filter hallucination
            if self.hallucination_check_enabled:
                self._validate_transcript(transcript_text)

            # Build response
            result = {"transcript": transcript_text, "language": detected_language}

            # Add additional metadata if available (verbose_json format)
            if hasattr(transcription, "duration"):
                result["duration"] = transcription.duration
            if hasattr(transcription, "words"):
                result["words"] = transcription.words

            return result

        except AudioValidationError:
            raise
        except HallucinationDetectedError:
            raise
        except openai.OpenAIError as e:
            self.logger.error(f"OpenAI API error: {str(e)}")
            raise WhisperAPIError(f"Whisper API error: {str(e)}") from e
        except Exception as e:
            self.logger.error(f"Transcription error: {str(e)}")
            raise WhisperTranscriptionError(
                f"Failed to transcribe audio: {str(e)}"
            ) from e
        finally:
            # Clean up temp file
            if temp_file_path:
                cleanup_temp_file(temp_file_path)

    async def transcribe_async(
        self,
        audio_input: Union[str, Path, bytes, BinaryIO],
        filename: Optional[str] = None,
        content_type: Optional[str] = None,
        prompt: Optional[str] = None,
        language: Optional[str] = None,
        response_format: str = "verbose_json",
        temperature: Optional[float] = None,
    ) -> Dict[str, Any]:
        """
        Transcribe audio file asynchronously.

        Same parameters and return value as transcribe(), but async.
        """
        import asyncio

        # Run sync method in executor for async compatibility
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None,
            lambda: self.transcribe(
                audio_input=audio_input,
                filename=filename,
                content_type=content_type,
                prompt=prompt,
                language=language,
                response_format=response_format,
                temperature=temperature,
            ),
        )

    def _validate_transcript(self, transcript: str) -> None:
        """
        Validate transcript and detect hallucinations.

        Args:
            transcript: Transcribed text

        Raises:
            HallucinationDetectedError: If hallucination is detected
            AudioValidationError: If transcript is too short
        """
        if not transcript:
            raise HallucinationDetectedError(
                "Empty transcript detected. No speech found in recording."
            )

        transcript_lower = transcript.lower().strip()

        # Check for emoji at start (common in hallucinations)
        if transcript and len(transcript) > 0:
            first_char = transcript[0]
            if ord(first_char) > 0x1F000:  # Emoji Unicode range
                raise HallucinationDetectedError(
                    f"Hallucination detected (emoji at start): '{transcript}'. "
                    "No speech detected in recording."
                )

        # Check for known hallucination phrases
        if transcript_lower in self.hallucination_phrases:
            raise HallucinationDetectedError(
                f"Hallucination detected: '{transcript}'. No speech detected in recording."
            )

        # Check for hallucination keywords in short transcripts
        if len(transcript) < 50:
            for keyword in self.hallucination_keywords:
                if keyword in transcript_lower:
                    raise HallucinationDetectedError(
                        f"Hallucination keyword '{keyword}' detected in short "
                        f"transcript: '{transcript}'. No speech detected in recording."
                    )

        # Check minimum length
        if len(transcript) < self.min_transcript_length:
            raise AudioValidationError(
                f"Transcript too short ({len(transcript)} chars). "
                f"Minimum length: {self.min_transcript_length} characters. "
                "Recording may be too short or unclear."
            )
