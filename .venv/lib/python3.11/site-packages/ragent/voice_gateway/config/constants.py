# constants.py - Static strings, status constants, and configuration values


# Session Status Constants
class SessionStatus:
    STARTING = "session_starting"
    CREATED = "session_created"
    CONNECTED = "connected"
    DISCONNECTED = "disconnected"
    ENDED = "session_ended"
    READY = "ready"
    ERROR = "error"


# OpenAI Message Types
class OpenAIMessageTypes:
    SESSION_CREATED = "session.created"
    SESSION_UPDATED = "session.updated"
    INPUT_AUDIO_BUFFER_COMMITTED = "input_audio_buffer.committed"
    CONVERSATION_ITEM_CREATED = "conversation.item.created"
    CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_DELTA = (
        "conversation.item.input_audio_transcription.delta"
    )
    CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED = (
        "conversation.item.input_audio_transcription.completed"
    )
    RESPONSE_CREATED = "response.created"
    RESPONSE_AUDIO_DELTA = "response.audio.delta"
    RESPONSE_DONE = "response.done"
    RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE = "response.function_call_arguments.done"
    ERROR = "error"
    INPUT_AUDIO_BUFFER_APPEND = "input_audio_buffer.append"
    INPUT_AUDIO_BUFFER_COMMIT = "input_audio_buffer.commit"
    CONVERSATION_ITEM_CREATE = "conversation.item.create"
    RESPONSE_CREATE = "response.create"


# Socket Events
class SocketEvents:
    CONNECT = "connect"
    DISCONNECT = "disconnect"
    START_SESSION = "start_session"
    AUDIO_DATA = "audio_data"
    COMMIT_AUDIO = "commit_audio"
    AUDIO_COMMITTED = "audio_committed"
    END_SESSION = "end_session"
    PING = "ping"
    PONG = "pong"
    CONNECTION_ESTABLISHED = "connection_established"
    SESSION_STARTING = "session_starting"
    SESSION_CREATED = "session_created"
    SESSION_STARTED = "session_started"
    SESSION_ENDED = "session_ended"
    AI_RESPONSE = "ai_response"
    RESPONSE_AUDIO = "response_audio"
    RESPONSE_DONE = "response_done"
    ERROR = "error"


# Static Messages
class Messages:
    CONNECTION_ESTABLISHED = (
        'Connected to Voice Gateway server. Click "Start Session" to begin.'
    )
    PING_PONG = "Ping received, sending pong"
    NO_AUDIO_DATA = "No audio data received"
    EMPTY_TRANSCRIPT_WARNING = "Empty transcript received, skipping processing"
    TTS_UNAVAILABLE = "TTS unavailable, text-only response sent"
    SESSION_NOT_FOUND = "No session found for client"
    NO_ACTIVE_SESSION = "No active session for client"
    NO_OPENAI_CONNECTION = "No OpenAI connection for client"
    FAILED_TO_SEND_AUDIO = "Failed to send audio to OpenAI"
    FAILED_TO_COMMIT_AUDIO = "Failed to commit audio to OpenAI"
    FAILED_TO_ESTABLISH_CONNECTION = "Failed to establish WebSocket connection"
    FAILED_TO_CONNECT = "Failed to connect"
    AUDIO_PROCESSING_ERROR = "Audio processing error"
    COMMIT_ERROR = "Commit error"
    CONNECTION_ERROR = "Connection error"
    TTS_ERROR = "TTS error"
    OPENAI_ERROR = "OpenAI Error"
    UNEXPECTED_ERROR = "Unexpected error"
    FALLBACK_RESPONSE_PREFIX = "I encountered an error processing your request"
    HEALTH_STATUS_HEALTHY = "healthy"
    HEALTH_STATUS_UNHEALTHY = "unhealthy"


# OpenAI Configuration Defaults (matching realtime_api)
class OpenAIConfig:
    # Model and voice (matching realtime_api defaults)
    VOICE_MODEL = "gpt-realtime-2025-08-28"
    # WebSocket URL pattern (used to build dynamic URL based on voice_model)
    WEBSOCKET_URL = f"wss://api.openai.com/v1/realtime?model={VOICE_MODEL}"
    VOICE = "alloy"

    # Transcription (matching realtime_api: {"model": "whisper-1"})
    TRANSCRIPTION_MODEL = "whisper-1"

    # Turn detection (matching realtime_api: None = manual control)
    # Note: realtime_api uses turn_detection: None (not a string)
    # For overrides, projects can pass: "disabled" (maps to None), "normal", or "semantic"
    TURN_DETECTION_MODE = "disabled"  # Maps to None (realtime_api default)
    TURN_DETECTION_MAP = {
        "disabled": None,  # Manual control (realtime_api default)
        "normal": {"type": "server_vad"},
        "semantic": {"type": "server_vad", "mode": "semantic"},
    }

    # Max tokens (matching realtime_api: "inf")
    # Note: Dashboard shows max 4096, but API accepts "inf" (realtime_api uses "inf")
    MAX_OUTPUT_TOKENS = "inf"

    # Noise reduction (optional - not in realtime_api, but available in OpenAI dashboard)
    # Projects can override this if needed, but it's not in realtime_api by default
    NOISE_REDUCTION_MODE = "near_field"  # near_field | far_field
    NOISE_REDUCTION_OPTIONS = {"near_field", "far_field"}

    # Session configuration (matching realtime_api)
    MODALITIES = ["text", "audio"]
    INSTRUCTIONS = (
        "You are a speech transcription and text-to-speech assistant. "
        "Transcribe audio to text and read text aloud exactly as provided, "
        "word for word, in clear English without modifications."
    )
    TTS_INSTRUCTIONS = (
        "You are a text-to-speech reader. Read only the exact "
        "text provided in the user message, word for word, "
        "without any additions, modifications, or commentary. "
        "Speak clearly in English language only."
    )
    TTS_PREFIX = (
        "Please read this text exactly as written, "
        "word for word, without adding any commentary: "
    )


# Audio Configuration
class AudioConfig:
    MIN_DURATION_MS = 1000
    PING_INTERVAL = 20
    PING_TIMEOUT = 120


# Service Names
class ServiceNames:
    VOICE_GATEWAY = "voice_gateway"


# Log Section Headers
class LogSections:
    CLIENT_CONNECTED = "=== Client Connected ==="
    CLIENT_DISCONNECTING = "=== Client Disconnecting ==="
    CLIENT_DISCONNECTED = "=== Client Disconnected ==="
    STARTING_VOICE_SESSION = "=== Starting Voice Session ==="
    ENDING_VOICE_SESSION = "=== Ending Voice Session ==="
    COMMITTING_AUDIO = "=== Committing Audio ==="
    STARTING_PROCESS_AND_RESPOND = "=== Starting _process_and_respond ==="
    PROCESS_AND_RESPOND_COMPLETED = "=== _process_and_respond completed in {:.3f}s ==="
    STARTING_CREATE_VOICE_RESPONSE = "=== Starting _create_voice_response ==="
    CREATE_VOICE_RESPONSE_COMPLETED = (
        "=== _create_voice_response completed in {:.3f}s ==="
    )


# HTTP Headers
class Headers:
    USER_AGENT = "User-Agent"
    AUTHORIZATION = "Authorization"
    OPENAI_BETA = "OpenAI-Beta"


# Error Codes
class ErrorCodes:
    CONFIGURATION_ERROR = "CONFIGURATION_ERROR"
    SESSION_ERROR = "SESSION_ERROR"
    AUDIO_ERROR = "AUDIO_ERROR"
    WEBSOCKET_ERROR = "WEBSOCKET_ERROR"
